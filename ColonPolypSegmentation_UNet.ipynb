{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation of Colon Polyps from Colonscopy Video: \n",
    "## UNet Model | CS230 | Christian H. Nunez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from __future__ import division\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import json,codecs\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "## Seeding \n",
    "seed = 2019\n",
    "random.seed = seed\n",
    "#np.random.seed = seed\n",
    "tf.seed = seed\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities for tuning\n",
    "def saveHist(path,history):\n",
    "    new_hist = {}\n",
    "    for key in list(history.history.keys()):\n",
    "        if type(history.history[key]) == np.ndarray:\n",
    "            new_hist[key] == history.history[key].tolist()\n",
    "        elif type(history.history[key]) == list:\n",
    "           if  type(history.history[key][0]) == np.float64:\n",
    "               new_hist[key] = list(map(float, history.history[key]))\n",
    "\n",
    "    print(new_hist)\n",
    "    with codecs.open(path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(new_hist, f, separators=(',', ':'), sort_keys=True, indent=4) \n",
    "\n",
    "def loadHist(path):\n",
    "    with codecs.open(path, 'r', encoding='utf-8') as f:\n",
    "        n = json.loads(f.read())\n",
    "    return n\n",
    "\n",
    "#Credit: https://stackoverflow.com/questions/41061457/keras-how-to-save-the-training-history/53101097"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Work (U-Net, no data augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom data generator (easy to use when analyzing predictions)\n",
    "class DataGen(keras.utils.Sequence):\n",
    "    def __init__(self, ids, path, batch_size=8, image_size=128):\n",
    "        self.ids = ids\n",
    "        self.path = path\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.on_epoch_end()\n",
    "     \n",
    "    def __load__(self, id_name):\n",
    "        ## Path\n",
    "        image_path = os.path.join(self.path, \"Org\", id_name) + \".png\"\n",
    "        mask_path = os.path.join(self.path, \"GT\", id_name) + \".png\"\n",
    "        \n",
    "        ## Reading Image\n",
    "        image = cv2.imread(image_path, 1)\n",
    "        image = cv2.resize(image, (self.image_size, self.image_size))\n",
    "        #image = np.expand_dims(image, axis=-1)\n",
    "        \n",
    "        ## Reading Masks\n",
    "        mask = cv2.imread(mask_path, 0)\n",
    "        mask = cv2.resize(mask, (self.image_size, self.image_size))\n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "        #mask = np.maximum(np.zeros((self.image_size, self.image_size, 1)), mask)\n",
    "                    \n",
    "        ## Normalizaing \n",
    "        image = image/255.0\n",
    "        mask = mask/255.0\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if(index+1)*self.batch_size > len(self.ids):\n",
    "            self.batch_size = len(self.ids) - index*self.batch_size\n",
    "        \n",
    "        files_batch = self.ids[index*self.batch_size : (index+1)*self.batch_size]\n",
    "        \n",
    "        image = []\n",
    "        mask  = []\n",
    "        \n",
    "        for id_name in files_batch:\n",
    "            _img, _mask = self.__load__(id_name)\n",
    "            image.append(_img)\n",
    "            mask.append(_mask)\n",
    "            \n",
    "        image = np.array(image)\n",
    "        mask  = np.array(mask)\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.ids)/float(self.batch_size)))\n",
    "\n",
    "# Cell credit: https://github.com/nikhilroxtomar/UNet-Segmentation-in-Keras-TensorFlow/blob/master/unet-segmentation.ipynb\n",
    "# __load__ function modified significantly to account for different file structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 128\n",
    "train_path = \"/Users/ChristianHaroldNunez/Desktop/colons/CVC-ClinicDB/\"\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "\n",
    "# Data Sizes\n",
    "val_data_size = 18\n",
    "test_data_size = 12\n",
    "\n",
    "## Get training ids from original photo files\n",
    "train_ids = os.listdir(train_path + \"Org_9/\")\n",
    "total_images = len(train_ids)\n",
    "for i in range(len(train_ids)):\n",
    "    train_ids[i] = train_ids[i].split(\".\")[0]\n",
    "\n",
    "# Choose train, train-dev (validation), dev, test split:\n",
    "# 1 : Train and Train-Dev come from the same set of videos (SET A),\n",
    "#     dev comes from a different set of videos (SET B), \n",
    "#     and test comes from a different set of videos (SET C).\n",
    "#\n",
    "# 0 : Random shuffle into train, train-dev, test.\n",
    "option = 1\n",
    "valid_ids = []\n",
    "dev_ids = []\n",
    "test_ids = []\n",
    "\n",
    "if option == 1:\n",
    "    train_ids = (np.sort(np.array(train_ids).astype(int))).astype(str)\n",
    "    # Take 1.png through 25.png as the test set (all from one video)\n",
    "    test_ids = train_ids[:25]\n",
    "    # Take 26.png through 50.png as the dev set (all from one video)\n",
    "    dev_ids = train_ids[25:50]\n",
    "    # Split train_ids into train_ids and valid_ids\n",
    "    train_ids = train_ids[50:]\n",
    "    random.shuffle(train_ids)\n",
    "    valid_ids = train_ids[:val_data_size]\n",
    "    train_ids = train_ids[val_data_size:]\n",
    "    \n",
    "else:\n",
    "    random.shuffle(train_ids)\n",
    "    valid_ids = train_ids[:val_data_size]\n",
    "    test_ids = train_ids[val_data_size:(val_data_size+test_data_size)]\n",
    "    train_ids = train_ids[(val_data_size+test_data_size):]\n",
    "\n",
    "print(\" ==== TRAIN-DEV-TEST ==== \")\n",
    "print(\"Image size %d x %d\"%(image_size, image_size))\n",
    "print(\"Total images: %d\"%total_images)\n",
    "print(\"Train data: %d frames (%s%%)\"%(len(train_ids), (str)(len(train_ids) * 100/total_images)))\n",
    "print(\"Validation data: %d frames (%s%%)\"%(len(valid_ids), (str)(len(valid_ids)*100/total_images)))\n",
    "print(\"Dev data: %d frames (%s%%)\"%(len(dev_ids), (str)(len(dev_ids)*100/total_images)))\n",
    "print(\"Test data: %d frames (%s%%)\"%(len(test_ids), (str)(len(test_ids)*100/total_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = DataGen(train_ids, train_path, batch_size=len(train_ids), image_size=image_size)\n",
    "x, y = gen.__getitem__(0)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View a random training image and mask:\n",
    "r = random.randint(0, len(x)-1) + 4\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.imshow(x[r])\n",
    "ax.set_title(\"Actual Image\")\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.set_title(\"Ground Truth Mask\")\n",
    "ax.imshow(np.reshape(y[r], (image_size, image_size)), cmap=\"gray\")\n",
    "plt.savefig('examplepair.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimenting with overlaying the mask on the image (for presentation, not for the model)\n",
    "def mask_overlay(image, mask, color=(0, 255, 0)):\n",
    "    \"\"\"\n",
    "    Helper function to visualize mask on the top of the car\n",
    "    \"\"\"\n",
    "    mask = np.dstack((mask, mask, mask)) * np.array(color)\n",
    "    mask = mask.astype(np.uint8)\n",
    "    weighted_sum = cv2.addWeighted(mask, 0.5, image, 0.5, 0.)\n",
    "    img = image.copy()\n",
    "    ind = mask[:, :, 1] > 0    \n",
    "    img[ind] = weighted_sum[ind]    \n",
    "    return img\n",
    "# Cell credit: https://github.com/ternaus/robot-surgery-segmentation/blob/master/Demo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the overlay:\n",
    "def load_image(path):\n",
    "    img = cv2.imread(str(path))\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "im = load_image(\"/Users/ChristianHaroldNunez/Desktop/colons/CVC-ClinicDB/Org/188.png\")\n",
    "msk = cv2.imread(\"/Users/ChristianHaroldNunez/Desktop/colons/CVC-ClinicDB/GT/188.png\", 0)\n",
    "msk = np.expand_dims(msk, axis=-1)\n",
    "a = mask_overlay(im, (msk>0).astype(np.uint8))\n",
    "img = Image.fromarray(a, 'RGB')\n",
    "\n",
    "\n",
    "# Plot the figures:\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "ax[0].imshow(im)\n",
    "ax[1].imshow(img)\n",
    "ax[2].imshow(np.reshape(msk, (im.shape[0], im.shape[1])), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet Architecture Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    p = keras.layers.MaxPool2D((2, 2), (2, 2))(c)\n",
    "    return c, p\n",
    "\n",
    "def up_block(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    us = keras.layers.UpSampling2D((2, 2))(x)\n",
    "    concat = keras.layers.Concatenate()([us, skip])\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(concat)\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    return c\n",
    "\n",
    "def bottleneck(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    return c\n",
    "\n",
    "# Cell credit: https://github.com/nikhilroxtomar/UNet-Segmentation-in-Keras-TensorFlow/blob/master/unet-segmentation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNet():\n",
    "    f = [16, 32, 64, 128, 256]\n",
    "    inputs = keras.layers.Input((image_size, image_size, 3))\n",
    "    \n",
    "    p0 = inputs\n",
    "    c1, p1 = down_block(p0, f[0]) #128 -> 64\n",
    "    c2, p2 = down_block(p1, f[1]) #64 -> 32\n",
    "    c3, p3 = down_block(p2, f[2]) #32 -> 16\n",
    "    c4, p4 = down_block(p3, f[3]) #16->8\n",
    "    \n",
    "    bn = bottleneck(p4, f[4])\n",
    "    \n",
    "    u1 = up_block(bn, c4, f[3]) #8 -> 16\n",
    "    u2 = up_block(u1, c3, f[2]) #16 -> 32\n",
    "    u3 = up_block(u2, c2, f[1]) #32 -> 64\n",
    "    u4 = up_block(u3, c1, f[0]) #64 -> 128\n",
    "    \n",
    "    outputs = keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(u4)\n",
    "    model = keras.models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Cell credit: https://github.com/nikhilroxtomar/UNet-Segmentation-in-Keras-TensorFlow/blob/master/unet-segmentation.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Custom Loss (Dice Coefficient Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = keras.backend.flatten(y_true)\n",
    "    y_pred_f = keras.backend.flatten(y_pred)\n",
    "    intersection = keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (keras.backend.sum(y_true_f) + keras.backend.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "# Dice coefficient implementation: https://forums.fast.ai/t/understanding-the-dice-coefficient/5838"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet()\n",
    "adam = keras.optimizers.Adam(lr=.0001)\n",
    "model.compile(optimizer=adam, loss=dice_coef_loss, metrics=[dice_coef, \"binary_accuracy\", 'mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training and validation batches\n",
    "train_gen = DataGen(train_ids, train_path, image_size=image_size, batch_size=batch_size)\n",
    "valid_gen = DataGen(valid_ids, train_path, image_size=image_size, batch_size=batch_size)\n",
    "\n",
    "# Compute training and validation steps\n",
    "train_steps = len(train_ids)//batch_size\n",
    "valid_steps = len(valid_ids)//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Optional: Preload weights\n",
    "#model.load_weights(\"/Users/ChristianHaroldNunez/Desktop/colons/best1.h5\")\n",
    "# === End preload weights\n",
    "\n",
    "# Standard\n",
    "epochs = 20\n",
    "model.fit_generator(train_gen, validation_data=valid_gen, steps_per_epoch=train_steps, validation_steps=valid_steps, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "model.save_weights(\"20_lr0001.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View an example of the prediction on one of the validation (train-dev) images\n",
    "x, y = valid_gen.__getitem__(1)\n",
    "print(valid_gen.__len__())\n",
    "result = model.predict(x)\n",
    "result = result > 0.5\n",
    "\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "\n",
    "# Predicted Mask\n",
    "ax[0].set_title(\"Actual Mask\")\n",
    "ax[0].imshow(np.reshape(y[0]*255, (image_size, image_size)), cmap=\"gray\")\n",
    "\n",
    "# Actual Mask'\n",
    "ax[1].set_title(\"Predicted Mask\")\n",
    "ax[1].imshow(np.reshape(result[0]*255, (image_size, image_size)), cmap=\"gray\")\n",
    "\n",
    "# Actual Image\n",
    "ax[2].set_title(\"Actual Image\")\n",
    "ax[2].imshow(np.reshape(x[0][:,:,0]*255, (image_size, image_size)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions with the Dev Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test time\n",
    "# ==============\n",
    "# Create datagen for the dev and test sets:\n",
    "test_gen = DataGen(test_ids, train_path, image_size=image_size, batch_size=len(test_ids))\n",
    "dev_gen = DataGen(dev_ids, train_path, image_size=image_size, batch_size=len(dev_ids))\n",
    "\n",
    "x, y = dev_gen.__getitem__(0)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with the images in the test:\n",
    "result = model.predict(x)\n",
    "result = result > 0.5\n",
    "\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "\n",
    "# SAVE ALL TEST_IMAGE TRIPLETS FOR VIEWING\n",
    "for n in range(len(test_ids)):\n",
    "    ax[0].set_title(\"Actual Mask\")\n",
    "    ax[0].imshow(np.reshape(y[n]*255, (image_size, image_size)), cmap=\"gray\")\n",
    "\n",
    "    # Actual Mask'\n",
    "    ax[1].set_title(\"Predicted Mask\")\n",
    "    ax[1].imshow(np.reshape(result[n]*255, (image_size, image_size)), cmap=\"gray\")\n",
    "\n",
    "    # Actual Image\n",
    "    ax[2].set_title(\"Actual Image\")\n",
    "    ax[2].imshow(np.reshape(x[n][:,:,0]*255, (image_size, image_size)), cmap=\"gray\")\n",
    "\n",
    "    plt.savefig(\"/Users/ChristianHaroldNunez/Desktop/colons/CVC-ClinicDB/saved_test_figs/\"+str(test_ids[n]))\n",
    "    \n",
    "plt.close()\n",
    "\n",
    "# Example output included in milestone report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.metrics_names)\n",
    "model.evaluate(x, y, batch_size=len(x), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved U-Net: Data Augmentation and Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet()\n",
    "adam = keras.optimizers.Adam(lr=.0001)\n",
    "rmsprop = keras.optimizers.RMSprop(lr=.0001)\n",
    "sgd = keras.optimizers.SGD(lr=.001, momentum=0.9)\n",
    "model.compile(optimizer=adam, loss=dice_coef_loss, metrics=[dice_coef, \"binary_accuracy\", 'mse'])\n",
    "#model.load_weights(\"20_lr0001.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import itertools as itt\n",
    "\n",
    "\n",
    "def combineGenerator(gen1, gen2):\n",
    "    while True:\n",
    "        #print(gen1.next()[0].shape, gen2.next()[0].shape)\n",
    "        yield(gen1.next()[0], gen2.next()[0])\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 1\n",
    "data_aug_path = '/Users/ChristianHaroldNunez/Desktop/colons/CVC-ClinicDB/data_aug2/'\n",
    "\n",
    "# Augmentation configuration for training:\n",
    "#--------\n",
    "# data_gen_args=dict(rescale=1./255,\n",
    "#         rotation_range=40,\n",
    "#         width_shift_range=0.2,\n",
    "#         height_shift_range=0.2,\n",
    "#         shear_range=0.1,\n",
    "#         brightness_range=(0.1, 0.8),\n",
    "#         horizontal_flip=True)\n",
    "\n",
    "data_gen_args=dict(rescale=1./255,\n",
    "        rotation_range=360,    \n",
    "        brightness_range=(0.4, 0.6),\n",
    "        vertical_flip=True,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "\n",
    "#data_gen_args=dict(rescale=1./255)\n",
    "# -------\n",
    "\n",
    "# Making image data for TRAINING images\n",
    "train_image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "train_mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "seed1 = 230\n",
    "\n",
    "train_image_generator = train_image_datagen.flow_from_directory(data_aug_path+'train/Org_upper',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    seed=seed1)\n",
    "\n",
    "train_mask_generator = train_mask_datagen.flow_from_directory(data_aug_path+'train/GT_upper',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    seed=seed1,\n",
    "    color_mode='grayscale')\n",
    "\n",
    "train_generator = combineGenerator(train_image_generator, train_mask_generator)\n",
    "\n",
    "# Making image data for VALIDATION images\n",
    "validation_image_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_mask_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_image_generator = validation_image_datagen.flow_from_directory(data_aug_path+'val/Org_upper',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    seed=seed1)\n",
    "\n",
    "validation_mask_generator = validation_mask_datagen.flow_from_directory(data_aug_path+'val/GT_upper',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    seed=seed1,\n",
    "    color_mode='grayscale')\n",
    "\n",
    "validation_generator = combineGenerator(validation_image_generator, validation_mask_generator)\n",
    "\n",
    "\n",
    "# Compute training and validation steps\n",
    "train_steps = 425//batch_size\n",
    "valid_steps = 50//batch_size\n",
    "\n",
    "print(type(validation_generator))\n",
    "\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_steps,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=valid_steps\n",
    ")\n",
    "\n",
    "model.save_weights('data_aug_HP6_nopretrained_lr0001_batch50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['dice_coef'], marker='o')\n",
    "plt.plot(history.history['val_dice_coef'], marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], marker='o')\n",
    "plt.plot(history.history['val_loss'], marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE YOUR HISTORY:\n",
    "saveHist('/Users/ChristianHaroldNunez/Desktop/colons/CVC-ClinicDB/HP5/data_aug_HP6_nopretrained_lr0001_batch50.json', history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test time\n",
    "# ==============\n",
    "# Create datagen for the dev and test sets:\n",
    "test_gen = DataGen(test_ids, train_path, image_size=image_size, batch_size=len(test_ids))\n",
    "dev_gen = DataGen(dev_ids, train_path, image_size=image_size, batch_size=len(dev_ids))\n",
    "\n",
    "x, y = test_gen.__getitem__(0)\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "print(model.metrics_names)\n",
    "model.evaluate(x, y, batch_size=len(x), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum training dice:\n",
    "print(\"Max train dice_coef:\", max(history.history[\"dice_coef\"]))\n",
    "print(\"Max val_dice_coef: \", max(history.history[\"val_dice_coef\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# PREPARING TRAINING/DEV SETS\n",
    "# ---------------------------\n",
    "image_size1 = 128\n",
    "train_path1 = \"/Users/ChristianHaroldNunez/Desktop/colons/CVC-ClinicDB/\"\n",
    "\n",
    "# Training set image demarcations\n",
    "\n",
    "\n",
    "## Get training ids from original photo files\n",
    "train_ids1 = os.listdir(train_path1 + \"Org/\")\n",
    "total_images1 = len(train_ids1)\n",
    "for i in range(len(train_ids1)):\n",
    "    train_ids1[i] = train_ids1[i].split(\".\")[0]\n",
    "    \n",
    "# Initialize ID lists\n",
    "valid_ids1 = []\n",
    "dev_ids1 = []\n",
    "test_ids1 = []\n",
    "\n",
    "train_ids1 = (np.sort(np.array(train_ids1).astype(int))).astype(str)\n",
    "\n",
    "seq_ends = [0, 25, 50, 67, 78, 103, 126, 151, 177]\n",
    "\n",
    "evals = []\n",
    "for s in range(2, len(seq_ends)-1):\n",
    "    tester_ids = train_ids1[seq_ends[s]:seq_ends[s+1]]\n",
    "    print(tester_ids)\n",
    "    # Test of those^\n",
    "    test_genner = DataGen(tester_ids, train_path1, image_size=image_size1, batch_size=len(tester_ids))\n",
    "    x, y = test_genner.__getitem__(0)\n",
    "    evals.append(model.evaluate(x, y, batch_size=len(x), verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = 0\n",
    "for i in range(len(evals)):\n",
    "    tot = tot + evals[i][1]\n",
    "    print(\"dice_coef: \", evals[i][1])\n",
    "\n",
    "print(\"avg in test set: \", tot/len(evals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with the images in the test:\n",
    "result = model.predict(x)\n",
    "result = result > 0.5\n",
    "\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "\n",
    "# SAVE ALL TEST_IMAGE TRIPLETS FOR VIEWING\n",
    "for n in range(len(test_ids)):\n",
    "    ax[0].set_title(\"Actual Mask\")\n",
    "    ax[0].imshow(np.reshape(y[n]*255, (image_size, image_size)), cmap=\"gray\")\n",
    "\n",
    "    # Actual Mask'\n",
    "    ax[1].set_title(\"Predicted Mask\")\n",
    "    ax[1].imshow(np.reshape(result[n]*255, (image_size, image_size)), cmap=\"gray\")\n",
    "\n",
    "    # Actual Image\n",
    "    ax[2].set_title(\"Actual Image\")\n",
    "    ax[2].imshow(np.reshape(x[n][:,:,0]*255, (image_size, image_size)), cmap=\"gray\")\n",
    "\n",
    "    plt.savefig(\"/Users/ChristianHaroldNunez/Desktop/colons/CVC-ClinicDB/HP2/saved_test_figs_TEST_Seq1_60+180/\"+str(test_ids[n]))\n",
    "    \n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA AUGMENTATION EXPERIMENTS:\n",
    "# Use this to output preview augmented images to a folder.\n",
    "\n",
    "data_gen_args=dict(rescale=1./255,\n",
    "        zca_whitening=True,\n",
    "        rotation_range=360,    \n",
    "        brightness_range=(0.1, 0.9),\n",
    "        vertical_flip=True,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "num = '512'\n",
    "img = load_img(\"/Users/ChristianHaroldNunez/Desktop/colons/CVC-ClinicDB/GT/\" + num + \".png\")  # this is a PIL image\n",
    "x = img_to_array(img)\n",
    "\n",
    "print(type(x), x.shape)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "# Saving some example augmented images to my \"previews\" directory\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='/Users/ChristianHaroldNunez/Desktop/colons/previews', save_prefix=num, save_format='png'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely\n",
    "        \n",
    "# Inspiration: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
