{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SegNet Implementation (Colon Polyp Segmentation) | Christian H. Nunez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristianHaroldNunez/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from __future__ import division\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Activation, Reshape\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Layer\n",
    "from PIL import Image\n",
    "import codecs, json\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "## Seeding \n",
    "seed = 2019\n",
    "random.seed = seed\n",
    "tf.seed = seed\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constants\n",
    "image_size = 128\n",
    "train_path = \"/Users/ChristianHaroldNunez/Desktop/colons/CVC-ClinicDB/\"\n",
    "epochs = 10\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def saveHist(path,history):\n",
    "    new_hist = {}\n",
    "    for key in list(history.history.keys()):\n",
    "        if type(history.history[key]) == np.ndarray:\n",
    "            new_hist[key] == history.history[key].tolist()\n",
    "        elif type(history.history[key]) == list:\n",
    "           if  type(history.history[key][0]) == np.float64:\n",
    "               new_hist[key] = list(map(float, history.history[key]))\n",
    "\n",
    "    print(new_hist)\n",
    "    with codecs.open(path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(new_hist, f, separators=(',', ':'), sort_keys=True, indent=4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SegNet base: https://github.com/ykamikawa/tf-keras-SegNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolingWithArgmax2D(Layer):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            pool_size=(2, 2),\n",
    "            strides=(2, 2),\n",
    "            padding='same',\n",
    "            **kwargs):\n",
    "        super(MaxPoolingWithArgmax2D, self).__init__(**kwargs)\n",
    "        self.padding = padding\n",
    "        self.pool_size = pool_size\n",
    "        self.strides = strides\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        padding = self.padding\n",
    "        pool_size = self.pool_size\n",
    "        strides = self.strides\n",
    "        if K.backend() == 'tensorflow':\n",
    "            ksize = [1, pool_size[0], pool_size[1], 1]\n",
    "            padding = padding.upper()\n",
    "            strides = [1, strides[0], strides[1], 1]\n",
    "            output, argmax = K.tf.nn.max_pool_with_argmax(\n",
    "                    inputs,\n",
    "                    ksize=ksize,\n",
    "                    strides=strides,\n",
    "                    padding=padding)\n",
    "        else:\n",
    "            errmsg = '{} backend is not supported for layer {}'.format(\n",
    "                    K.backend(), type(self).__name__)\n",
    "            raise NotImplementedError(errmsg)\n",
    "        argmax = K.cast(argmax, K.floatx())\n",
    "        return [output, argmax]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        ratio = (1, 2, 2, 1)\n",
    "        output_shape = [\n",
    "                dim//ratio[idx]\n",
    "                if dim is not None else None\n",
    "                for idx, dim in enumerate(input_shape)]\n",
    "        output_shape = tuple(output_shape)\n",
    "        return [output_shape, output_shape]\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return 2 * [None]\n",
    "\n",
    "\n",
    "class MaxUnpooling2D(Layer):\n",
    "    def __init__(self, size=(2, 2), **kwargs):\n",
    "        super(MaxUnpooling2D, self).__init__(**kwargs)\n",
    "        self.size = size\n",
    "\n",
    "    def call(self, inputs, output_shape=None):\n",
    "        updates, mask = inputs[0], inputs[1]\n",
    "        with K.tf.variable_scope(self.name):\n",
    "            mask = K.cast(mask, 'int32')\n",
    "            input_shape = K.tf.shape(updates, out_type='int32')\n",
    "            #  calculation new shape\n",
    "            if output_shape is None:\n",
    "                output_shape = (\n",
    "                        input_shape[0],\n",
    "                        input_shape[1]*self.size[0],\n",
    "                        input_shape[2]*self.size[1],\n",
    "                        input_shape[3])\n",
    "            self.output_shape1 = output_shape\n",
    "\n",
    "            # calculation indices for batch, height, width and feature maps\n",
    "            one_like_mask = K.ones_like(mask, dtype='int32')\n",
    "            batch_shape = K.concatenate(\n",
    "                    [[input_shape[0]], [1], [1], [1]],\n",
    "                    axis=0)\n",
    "            batch_range = K.reshape(\n",
    "                    K.tf.range(output_shape[0], dtype='int32'),\n",
    "                    shape=batch_shape)\n",
    "            b = one_like_mask * batch_range\n",
    "            y = mask // (output_shape[2] * output_shape[3])\n",
    "            x = (mask // output_shape[3]) % output_shape[2]\n",
    "            feature_range = K.tf.range(output_shape[3], dtype='int32')\n",
    "            f = one_like_mask * feature_range\n",
    "\n",
    "            # transpose indices & reshape update values to one dimension\n",
    "            updates_size = K.tf.size(updates)\n",
    "            indices = K.transpose(K.reshape(\n",
    "                K.stack([b, y, x, f]),\n",
    "                [4, updates_size]))\n",
    "            values = K.reshape(updates, [updates_size])\n",
    "            ret = K.tf.scatter_nd(indices, values, output_shape)\n",
    "            return ret\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        mask_shape = input_shape[1]\n",
    "        return (\n",
    "                mask_shape[0],\n",
    "                mask_shape[1]*self.size[0],\n",
    "                mask_shape[2]*self.size[1],\n",
    "                mask_shape[3]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segnet(\n",
    "        input_shape,\n",
    "        n_labels,\n",
    "        kernel=3,\n",
    "        pool_size=(2, 2),\n",
    "        output_mode=\"softmax\"):\n",
    "    # encoder\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    conv_1 = Convolution2D(64, (kernel, kernel), padding=\"same\")(inputs)\n",
    "    conv_1 = BatchNormalization()(conv_1)\n",
    "    conv_1 = Activation(\"relu\")(conv_1)\n",
    "    conv_2 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_1)\n",
    "    conv_2 = BatchNormalization()(conv_2)\n",
    "    conv_2 = Activation(\"relu\")(conv_2)\n",
    "\n",
    "    pool_1, mask_1 = MaxPoolingWithArgmax2D(pool_size)(conv_2)\n",
    "\n",
    "    conv_3 = Convolution2D(128, (kernel, kernel), padding=\"same\")(pool_1)\n",
    "    conv_3 = BatchNormalization()(conv_3)\n",
    "    conv_3 = Activation(\"relu\")(conv_3)\n",
    "    conv_4 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_3)\n",
    "    conv_4 = BatchNormalization()(conv_4)\n",
    "    conv_4 = Activation(\"relu\")(conv_4)\n",
    "\n",
    "    pool_2, mask_2 = MaxPoolingWithArgmax2D(pool_size)(conv_4)\n",
    "\n",
    "    conv_5 = Convolution2D(256, (kernel, kernel), padding=\"same\")(pool_2)\n",
    "    conv_5 = BatchNormalization()(conv_5)\n",
    "    conv_5 = Activation(\"relu\")(conv_5)\n",
    "    conv_6 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_5)\n",
    "    conv_6 = BatchNormalization()(conv_6)\n",
    "    conv_6 = Activation(\"relu\")(conv_6)\n",
    "    conv_7 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_6)\n",
    "    conv_7 = BatchNormalization()(conv_7)\n",
    "    conv_7 = Activation(\"relu\")(conv_7)\n",
    "\n",
    "    pool_3, mask_3 = MaxPoolingWithArgmax2D(pool_size)(conv_7)\n",
    "\n",
    "    conv_8 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_3)\n",
    "    conv_8 = BatchNormalization()(conv_8)\n",
    "    conv_8 = Activation(\"relu\")(conv_8)\n",
    "    conv_9 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_8)\n",
    "    conv_9 = BatchNormalization()(conv_9)\n",
    "    conv_9 = Activation(\"relu\")(conv_9)\n",
    "    conv_10 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_9)\n",
    "    conv_10 = BatchNormalization()(conv_10)\n",
    "    conv_10 = Activation(\"relu\")(conv_10)\n",
    "\n",
    "    pool_4, mask_4 = MaxPoolingWithArgmax2D(pool_size)(conv_10)\n",
    "\n",
    "    conv_11 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_4)\n",
    "    conv_11 = BatchNormalization()(conv_11)\n",
    "    conv_11 = Activation(\"relu\")(conv_11)\n",
    "    conv_12 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_11)\n",
    "    conv_12 = BatchNormalization()(conv_12)\n",
    "    conv_12 = Activation(\"relu\")(conv_12)\n",
    "    conv_13 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_12)\n",
    "    conv_13 = BatchNormalization()(conv_13)\n",
    "    conv_13 = Activation(\"relu\")(conv_13)\n",
    "\n",
    "    pool_5, mask_5 = MaxPoolingWithArgmax2D(pool_size)(conv_13)\n",
    "    print(\"Build encoder done..\")\n",
    "\n",
    "    # decoder\n",
    "\n",
    "    unpool_1 = MaxUnpooling2D(pool_size)([pool_5, mask_5])\n",
    "\n",
    "    conv_14 = Convolution2D(512, (kernel, kernel), padding=\"same\")(unpool_1)\n",
    "    conv_14 = BatchNormalization()(conv_14)\n",
    "    conv_14 = Activation(\"relu\")(conv_14)\n",
    "    conv_15 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_14)\n",
    "    conv_15 = BatchNormalization()(conv_15)\n",
    "    conv_15 = Activation(\"relu\")(conv_15)\n",
    "    conv_16 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_15)\n",
    "    conv_16 = BatchNormalization()(conv_16)\n",
    "    conv_16 = Activation(\"relu\")(conv_16)\n",
    "\n",
    "    unpool_2 = MaxUnpooling2D(pool_size)([conv_16, mask_4])\n",
    "\n",
    "    conv_17 = Convolution2D(512, (kernel, kernel), padding=\"same\")(unpool_2)\n",
    "    conv_17 = BatchNormalization()(conv_17)\n",
    "    conv_17 = Activation(\"relu\")(conv_17)\n",
    "    conv_18 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_17)\n",
    "    conv_18 = BatchNormalization()(conv_18)\n",
    "    conv_18 = Activation(\"relu\")(conv_18)\n",
    "    conv_19 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_18)\n",
    "    conv_19 = BatchNormalization()(conv_19)\n",
    "    conv_19 = Activation(\"relu\")(conv_19)\n",
    "\n",
    "    unpool_3 = MaxUnpooling2D(pool_size)([conv_19, mask_3])\n",
    "\n",
    "    conv_20 = Convolution2D(256, (kernel, kernel), padding=\"same\")(unpool_3)\n",
    "    conv_20 = BatchNormalization()(conv_20)\n",
    "    conv_20 = Activation(\"relu\")(conv_20)\n",
    "    conv_21 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_20)\n",
    "    conv_21 = BatchNormalization()(conv_21)\n",
    "    conv_21 = Activation(\"relu\")(conv_21)\n",
    "    conv_22 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_21)\n",
    "    conv_22 = BatchNormalization()(conv_22)\n",
    "    conv_22 = Activation(\"relu\")(conv_22)\n",
    "\n",
    "    unpool_4 = MaxUnpooling2D(pool_size)([conv_22, mask_2])\n",
    "\n",
    "    conv_23 = Convolution2D(128, (kernel, kernel), padding=\"same\")(unpool_4)\n",
    "    conv_23 = BatchNormalization()(conv_23)\n",
    "    conv_23 = Activation(\"relu\")(conv_23)\n",
    "    conv_24 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_23)\n",
    "    conv_24 = BatchNormalization()(conv_24)\n",
    "    conv_24 = Activation(\"relu\")(conv_24)\n",
    "\n",
    "    unpool_5 = MaxUnpooling2D(pool_size)([conv_24, mask_1])\n",
    "\n",
    "    conv_25 = Convolution2D(64, (kernel, kernel), padding=\"same\")(unpool_5)\n",
    "    \n",
    "    outputs = Convolution2D(3, (1, 1), padding=\"same\", activation=\"sigmoid\")(conv_25)\n",
    "    \n",
    "    #conv_26 = Convolution2D(n_labels, (1, 1), padding=\"valid\")(conv_25)\n",
    "    #conv_26 = BatchNormalization()(conv_26)\n",
    "    #conv_26 = Reshape(\n",
    "            #(input_shape[0]*input_shape[1], n_labels),\n",
    "            #input_shape=(input_shape[0], input_shape[1], n_labels))(conv_26)\n",
    "\n",
    "    #outputs = Activation(output_mode)(conv_26)\n",
    "    print(\"Build decoder done..\")\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"SegNet\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build encoder done..\n",
      "Build decoder done..\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 64) 320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 128, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 128, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 64) 16448       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 128, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 128, 128, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling_with_argmax2d_1 (Ma [(None, 64, 64, 64), 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 128)  32896       max_pooling_with_argmax2d_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 128)  65664       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 128)  512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling_with_argmax2d_2 (Ma [(None, 32, 32, 128) 0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 256)  131328      max_pooling_with_argmax2d_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 256)  1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 256)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 256)  262400      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 256)  262400      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 256)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling_with_argmax2d_3 (Ma [(None, 16, 16, 256) 0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 512)  524800      max_pooling_with_argmax2d_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 512)  2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 512)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 512)  1049088     activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 512)  2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 512)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 512)  1049088     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 512)  2048        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 512)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling_with_argmax2d_4 (Ma [(None, 8, 8, 512),  0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 512)    1049088     max_pooling_with_argmax2d_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 8, 512)    2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 8, 8, 512)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 512)    1049088     activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 512)    2048        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 8, 8, 512)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 512)    1049088     activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 512)    2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 512)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling_with_argmax2d_5 (Ma [(None, 4, 4, 512),  0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_unpooling2d_1 (MaxUnpooling (None, 8, 8, 512)    0           max_pooling_with_argmax2d_5[0][0]\n",
      "                                                                 max_pooling_with_argmax2d_5[0][1]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 512)    1049088     max_unpooling2d_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 512)    2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 512)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 512)    1049088     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 512)    2048        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 512)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 512)    1049088     activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 512)    2048        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 512)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_unpooling2d_2 (MaxUnpooling (None, 16, 16, 512)  0           activation_16[0][0]              \n",
      "                                                                 max_pooling_with_argmax2d_4[0][1]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 512)  1049088     max_unpooling2d_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 512)  2048        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 512)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 512)  1049088     activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 512)  2048        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 512)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 256)  524544      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 256)  1024        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 256)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_unpooling2d_3 (MaxUnpooling (None, 32, 32, 256)  0           activation_19[0][0]              \n",
      "                                                                 max_pooling_with_argmax2d_3[0][1]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 256)  262400      max_unpooling2d_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 256)  1024        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 256)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 256)  262400      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 256)  1024        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 256)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 128)  131200      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_unpooling2d_4 (MaxUnpooling (None, 64, 64, 128)  0           activation_22[0][0]              \n",
      "                                                                 max_pooling_with_argmax2d_2[0][1]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 64, 128)  65664       max_unpooling2d_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 64, 64, 128)  512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 64, 64, 128)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 64, 64, 64)   32832       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 64, 64, 64)   256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 64, 64, 64)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_unpooling2d_5 (MaxUnpooling (None, 128, 128, 64) 0           activation_24[0][0]              \n",
      "                                                                 max_pooling_with_argmax2d_1[0][1]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 128, 128, 64) 16448       max_unpooling2d_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 128, 128, 3)  195         conv2d_25[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 13,114,307\n",
      "Trainable params: 13,098,563\n",
      "Non-trainable params: 15,744\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set the model, optimizer. Compile and load weights, and summarize.\n",
    "model = segnet((128, 128,1), n_labels=2, kernel=2, pool_size=(2,2), output_mode=\"softmax\")\n",
    "adam = keras.optimizers.Adam(lr=.0001)\n",
    "model.compile(optimizer=adam, loss=dice_coef_loss, metrics=[dice_coef, \"binary_accuracy\", \"mse\"])\n",
    "model.load_weights(\"firsttry_2_50_50.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import itertools as itt\n",
    "\n",
    "\n",
    "def combineGenerator(gen1, gen2):\n",
    "    while True:\n",
    "        #print(gen1.next()[0].shape, gen2.next()[0].shape)\n",
    "        yield(gen1.next()[0], gen2.next()[0])\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 1\n",
    "data_aug_path = '/Users/ChristianHaroldNunez/Desktop/colons/CVC-ClinicDB/data_aug2/'\n",
    "\n",
    "\n",
    "data_gen_args=dict(rescale=1./255,\n",
    "        rotation_range=360,    \n",
    "        brightness_range=(0.4, 0.6),\n",
    "        vertical_flip=True,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "\n",
    "# Making image data for TRAINING images\n",
    "train_image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "train_mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "seed1 = 230\n",
    "\n",
    "train_image_generator = train_image_datagen.flow_from_directory(data_aug_path+'train/Org_upper',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    seed=seed1,\n",
    "    color_mode='grayscale')\n",
    "\n",
    "train_mask_generator = train_mask_datagen.flow_from_directory(data_aug_path+'train/GT_upper',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    seed=seed1)\n",
    "\n",
    "train_generator = combineGenerator(train_image_generator, train_mask_generator)\n",
    "\n",
    "\n",
    "# Making image data for VALIDATION images\n",
    "validation_image_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_mask_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_image_generator = validation_image_datagen.flow_from_directory(data_aug_path+'val/Org_upper',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    seed=seed1,\n",
    "    color_mode='grayscale')\n",
    "\n",
    "validation_mask_generator = validation_mask_datagen.flow_from_directory(data_aug_path+'val/GT_upper',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    seed=seed1)\n",
    "\n",
    "validation_generator = combineGenerator(validation_image_generator, validation_mask_generator)\n",
    "\n",
    "\n",
    "# Compute training and validation steps\n",
    "train_steps = 425//batch_size\n",
    "valid_steps = 50//batch_size\n",
    "\n",
    "print(type(validation_generator))\n",
    "\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_steps,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=valid_steps\n",
    ")\n",
    "\n",
    "\n",
    "model.save_weights('firsttry_2_50_50_10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the history (if desired)\n",
    "saveHist('/Users/ChristianHaroldNunez/Desktop/image-segmentation-keras/weights/segnet_dataaug_adam0001_2_50_50_10.json', \n",
    "         history)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, plot the history of the validation dice_coefficients:\n",
    "plt.plot(history.history['val_dice_coef'], marker='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom data generator -- easy to manage than ImageDataGenerator\n",
    "class DataGen(keras.utils.Sequence):\n",
    "    def __init__(self, ids, path, batch_size=8, image_size=128):\n",
    "        self.ids = ids\n",
    "        self.path = path\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.on_epoch_end()\n",
    "     \n",
    "    def __load__(self, id_name):\n",
    "        ## Path\n",
    "        image_path = os.path.join(self.path, \"Org\", id_name) + \".png\"\n",
    "        mask_path = os.path.join(self.path, \"GT\", id_name) + \".png\"\n",
    "        \n",
    "        ## Reading Image\n",
    "        image = cv2.imread(image_path, 1)\n",
    "        image = cv2.resize(image, (self.image_size, self.image_size))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        image = np.expand_dims(image, axis=-1)\n",
    "        \n",
    "        ## Reading Masks\n",
    "        mask = cv2.imread(mask_path, 0)\n",
    "        mask = cv2.resize(mask, (self.image_size, self.image_size))\n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "        #mask = np.maximum(np.zeros((self.image_size, self.image_size, 1)), mask)\n",
    "                    \n",
    "        ## Normalizaing \n",
    "        image = image/255.0\n",
    "        mask = mask/255.0\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if(index+1)*self.batch_size > len(self.ids):\n",
    "            self.batch_size = len(self.ids) - index*self.batch_size\n",
    "        \n",
    "        files_batch = self.ids[index*self.batch_size : (index+1)*self.batch_size]\n",
    "        \n",
    "        image = []\n",
    "        mask  = []\n",
    "        \n",
    "        for id_name in files_batch:\n",
    "            _img, _mask = self.__load__(id_name)\n",
    "            image.append(_img)\n",
    "            mask.append(_mask)\n",
    "            \n",
    "        image = np.array(image)\n",
    "        mask  = np.array(mask)\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.ids)/float(self.batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 127 images belonging to 1 classes.\n",
      "Found 127 images belonging to 1 classes.\n",
      "Found 425 images belonging to 1 classes.\n",
      "Found 425 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image data generators for viewing of test and train images. Filenames also collected.\n",
    "seed1 = 230\n",
    "test_image_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_mask_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_image_generator = test_image_datagen.flow_from_directory(data_aug_path+'test/Org_upper',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=1,\n",
    "    seed=seed1,\n",
    "    color_mode='grayscale')\n",
    "\n",
    "filenames = test_image_generator.filenames\n",
    "\n",
    "test_mask_generator = test_mask_datagen.flow_from_directory(data_aug_path+'test/GT_upper',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=1,\n",
    "    seed=seed1)\n",
    "\n",
    "test_generator = combineGenerator(test_image_generator, test_mask_generator)\n",
    "\n",
    "\n",
    "# See result on train images\n",
    "train_image_generator = train_image_datagen.flow_from_directory(data_aug_path+'train/Org_upper',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    seed=seed1,\n",
    "    color_mode='grayscale')\n",
    "\n",
    "filenames_train = train_image_generator.filenames\n",
    "\n",
    "train_mask_generator = train_mask_datagen.flow_from_directory(data_aug_path+'train/GT_upper',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    seed=seed1)\n",
    "\n",
    "train_generator = combineGenerator(train_image_generator, train_mask_generator)\n",
    "\n",
    "evals = model.evaluate_generator(test_generator, steps=127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'dice_coef', 'binary_accuracy', 'mean_squared_error']\n",
      "[-0.23329609211311514, 0.23329609211311514, 0.7862899646045655, 0.21000752598047256]\n"
     ]
    }
   ],
   "source": [
    "# Evaluations of SegNet on the test data:\n",
    "print(model.metrics_names)\n",
    "print(evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((425, 128, 128, 1), (425, 128, 128, 1))\n"
     ]
    }
   ],
   "source": [
    "# Filenames of test images from test_generator above\n",
    "test_ids = []\n",
    "trainer_ids = []\n",
    "for i in range(0, len(filenames)):\n",
    "    test_ids.append(str(filenames[i].split(\".\")[0].split(\"/\")[1]))\n",
    "\n",
    "for i in range(0, len(filenames_train)):\n",
    "    trainer_ids.append(str(filenames_train[i].split(\".\")[0].split(\"/\")[1]))\n",
    "\n",
    "train_path = \"/Users/ChristianHaroldNunez/Desktop/colons/CVC-ClinicDB/\"\n",
    "test_gen = DataGen(test_ids, train_path, image_size=image_size, batch_size=127)\n",
    "trainer_gen = DataGen(trainer_ids, train_path, image_size=image_size, batch_size=425)\n",
    "\n",
    "xx, yy = test_gen.__getitem__(0)\n",
    "xt, yt = trainer_gen.__getitem__(0)\n",
    "print(xt.shape, yt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 128, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 25\n",
    "x = np.expand_dims(xt[n], axis=0)\n",
    "y = np.expand_dims(yt[n], axis=0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 128, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "result = model.predict(x)\n",
    "\n",
    "result = result > 0.5\n",
    "result.shape\n",
    "# for i in range(0, 127):\n",
    "#     result = model.predict(np.expand_dims(x[i], axis=0))\n",
    "#     result = result > 0.5\n",
    "#     results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1828ac68d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x182a728cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 3)\n",
    "\n",
    "# Predicted Mask\n",
    "ax[0].set_title(\"Actual Mask\")\n",
    "ax[0].imshow(np.reshape(y[0]*255, (image_size, image_size)), cmap=\"gray\")\n",
    "\n",
    "# Actual Mask'\n",
    "ax[1].set_title(\"Predicted Mask\")\n",
    "ax[1].imshow(np.reshape(result[0][:,:,0]*255, (image_size, image_size)), cmap=\"gray\")\n",
    "\n",
    "# Actual Image\n",
    "ax[2].set_title(\"Actual Image\")\n",
    "ax[2].imshow(np.reshape(x[0][:,:,0]*255, (image_size, image_size)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SegNet predictions seem to localize the colon polyp somewhat well, but the masks are much grainier. Compare to the solid masks of the U-Net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
